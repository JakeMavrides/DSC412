{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import the TensorFlow Library, Switch to GPU, and Learn the Shape of your Data"
      ],
      "metadata": {
        "id": "r1X_aBVtmu6w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWKKQ3uqxf-b"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADVpjXhqxqAA",
        "outputId": "ce98ebed-549a-4e71-aa0b-bae3d7035105"
      },
      "source": [
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n",
            "/device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRuNpky7yQPY"
      },
      "source": [
        "#load data into an object called digits\n",
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMOpiGM1yvOm",
        "outputId": "73da082c-105b-43f6-8533-99e0f21d85e1"
      },
      "source": [
        "print(digits.keys())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "16qalzF-zybb",
        "outputId": "f3a9f18e-71a5-48a0-b40a-4492791d8157"
      },
      "source": [
        "digits.DESCR"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learn Classes/Labels/Output"
      ],
      "metadata": {
        "id": "YtC_c3TvnDx5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9DowCfvz2ok",
        "outputId": "f9283b55-e5e2-4860-f676-cd7249acf8d8"
      },
      "source": [
        "digits.target_names"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Take the Images Key and Pass it into the Variable \"Images\""
      ],
      "metadata": {
        "id": "Xwezfz8BnRU3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsuM2XbfW-7S"
      },
      "source": [
        "#load the images from the data set in to an array (3D) called images\n",
        "images = digits.images"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS1AMppWX8JY",
        "outputId": "17072bb8-57dd-4a0e-ad6a-f60588bd6e7d"
      },
      "source": [
        "images.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 8, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Store First Image in Dataset into Image0, Print, and Display as an Image"
      ],
      "metadata": {
        "id": "ikt1FB-M2PyF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "_5ud_WEQYEiT",
        "outputId": "16206856-03f5-4d00-853a-4251bc06c5e3"
      },
      "source": [
        "image0 = images[0]\n",
        "\n",
        "print(image0)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image0,cmap=\"binary\")\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
            " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
            " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
            " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
            " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
            " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
            " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
            " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Store the Labels/Answers/Output (Values of Classes) in Array called Targets"
      ],
      "metadata": {
        "id": "MpR5RMCe2i-s"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LTou-w1Yj00"
      },
      "source": [
        "targets = digits.target"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvIS88d6DaDa",
        "outputId": "0067b38f-d4ec-4009-d47b-9ceae0e706a4"
      },
      "source": [
        "targets.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUo6I_VBoBjc",
        "outputId": "4e543fd2-152d-4f03-fef0-900f0a323cd2"
      },
      "source": [
        "targets[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zupPf8XJEDWx",
        "outputId": "37a1ee9d-1033-416c-9ab7-cd7363b6ac89"
      },
      "source": [
        "print(targets)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 ... 8 9 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Store Flattened Version of Handwriting Specimens: Model will internally convert the 8X8 image into a 64 array"
      ],
      "metadata": {
        "id": "OOjX4ER_3zN5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJfxJt-g0DP6"
      },
      "source": [
        "#we will not be using the array data in training or testing the model\n",
        "#ignore digits.data\n",
        "data = digits.data"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaaasxKgW0QU",
        "outputId": "2cd113b7-7f39-47d0-e5ec-1ba9087e1a52"
      },
      "source": [
        "#not needed\n",
        "data.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyiFDbxmW6T2",
        "outputId": "3a09b34f-cd8a-4fc5-8610-26e34c6bf9bb"
      },
      "source": [
        "#not needed\n",
        "data.dtype"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eoGbkZqX4rL"
      },
      "source": [
        "#not needed\n",
        "data0 = data[0]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJxANnkvcX7M",
        "outputId": "481d84ff-01ea-4885-9b1e-d7bcac83306c"
      },
      "source": [
        "#not needed\n",
        "print(data0)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
            " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
            "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
            "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUHQQbkhcZKp",
        "outputId": "4fb99e54-47de-41cf-a6f8-741e67928b55"
      },
      "source": [
        "#Determine the data type of the arrays that store the numbers\n",
        "images.dtype"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Training and Test Datasets (Includes Features and Labels)"
      ],
      "metadata": {
        "id": "RHqI6YRv3iRc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5viTcQlsmD9J"
      },
      "source": [
        "#creatings training and test datasets (includes features and labels/targets)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, targets,test_size = 0.33, random_state=0)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN_di2Mzodx1",
        "outputId": "b1439775-0073-4b14-a0cc-7d3082ea3123"
      },
      "source": [
        "#X_train contains 1203 images (8x8) -- 67% of the overall data\n",
        "X_train.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1203, 8, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vV2M8KxpDug",
        "outputId": "83ddd903-c5ce-4b6c-d0de-cbd33858eb7e"
      },
      "source": [
        "#X_test contains 594 images (8x8) --  33% of the overall data set\n",
        "X_test.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(594, 8, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFO2ZyzvY0ne",
        "outputId": "ed19a8bb-c6b7-4b3d-f40c-a8b7a4f4bbb0"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1203,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_GNee7bGbgh",
        "outputId": "72d73697-0690-46c2-8c18-3592704b4a05"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(594,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvMfGBbppHsO"
      },
      "source": [
        "#normalizing the pixel values in the images to be in the range of\n",
        "#0 and 1\n",
        "s_train = X_train/16.0\n",
        "s_test = X_test/16.0"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NtNrvXAt0A9"
      },
      "source": [
        "#create a dataset that has both the features and labels needed for training\n",
        "#within the same dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((s_train, y_train))\n",
        "\n",
        "#create a dataset that has both the features and labels needed for testing\n",
        "#within the same dataset\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((s_test, y_test))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh2JLNx2oVc9",
        "outputId": "c23e8e1e-ed5f-4901-dc69-7a67dad9f26d"
      },
      "source": [
        "for item in train_dataset.take(2):\n",
        "  print(item)\n",
        "  print()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(8, 8), dtype=float64, numpy=\n",
            "array([[0.    , 0.    , 0.8125, 1.    , 1.    , 0.9375, 0.125 , 0.    ],\n",
            "       [0.    , 0.    , 0.875 , 0.8125, 0.6875, 1.    , 0.125 , 0.    ],\n",
            "       [0.    , 0.    , 0.6875, 0.8125, 0.9375, 0.375 , 0.    , 0.    ],\n",
            "       [0.    , 0.    , 0.3125, 1.    , 0.625 , 0.    , 0.    , 0.    ],\n",
            "       [0.    , 0.    , 0.625 , 0.875 , 0.9375, 0.    , 0.    , 0.    ],\n",
            "       [0.    , 0.0625, 0.875 , 0.1875, 0.9375, 0.4375, 0.    , 0.    ],\n",
            "       [0.    , 0.375 , 0.6875, 0.    , 0.9375, 0.375 , 0.    , 0.    ],\n",
            "       [0.    , 0.0625, 0.8125, 1.    , 0.9375, 0.1875, 0.    , 0.    ]])>, <tf.Tensor: shape=(), dtype=int64, numpy=8>)\n",
            "\n",
            "(<tf.Tensor: shape=(8, 8), dtype=float64, numpy=\n",
            "array([[0.    , 0.    , 0.    , 0.3125, 0.9375, 0.8125, 0.125 , 0.    ],\n",
            "       [0.    , 0.    , 0.    , 0.75  , 0.4375, 0.6875, 0.375 , 0.    ],\n",
            "       [0.    , 0.    , 0.    , 0.5625, 0.75  , 0.9375, 0.0625, 0.    ],\n",
            "       [0.    , 0.    , 0.0625, 0.5   , 1.    , 0.25  , 0.    , 0.    ],\n",
            "       [0.    , 0.1875, 0.9375, 0.5   , 0.8125, 0.    , 0.    , 0.    ],\n",
            "       [0.    , 0.4375, 0.75  , 0.    , 0.625 , 0.4375, 0.    , 0.    ],\n",
            "       [0.    , 0.    , 0.75  , 0.6875, 0.625 , 0.5   , 0.    , 0.    ],\n",
            "       [0.    , 0.    , 0.    , 0.375 , 0.8125, 0.625 , 0.    , 0.    ]])>, <tf.Tensor: shape=(), dtype=int64, numpy=8>)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N73XXhjojiu"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "#Shuffle and create batches of 64 images for training. There will be multiple such batches in train_ds\n",
        "train_ds = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "#shuffling is not needed in test_ds\n",
        "test_ds = test_dataset.batch(BATCH_SIZE)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQWyV54rU1w4",
        "outputId": "25665e1d-2a8c-45e5-b523-1442d84b5b5e"
      },
      "source": [
        "#let us look in to the first batch of train_ds\n",
        "for item in train_ds.take(1):\n",
        "  print(item)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(64, 8, 8), dtype=float64, numpy=\n",
            "array([[[0.    , 0.    , 0.6875, ..., 0.625 , 0.    , 0.    ],\n",
            "        [0.    , 0.375 , 0.9375, ..., 0.25  , 0.    , 0.    ],\n",
            "        [0.    , 0.3125, 0.75  , ..., 0.    , 0.    , 0.    ],\n",
            "        ...,\n",
            "        [0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ],\n",
            "        [0.    , 0.    , 0.3125, ..., 0.    , 0.    , 0.    ],\n",
            "        [0.    , 0.    , 0.8125, ..., 0.    , 0.    , 0.    ]],\n",
            "\n",
            "       [[0.    , 0.    , 0.625 , ..., 0.    , 0.    , 0.    ],\n",
            "        [0.    , 0.0625, 0.9375, ..., 0.375 , 0.    , 0.    ],\n",
            "        [0.    , 0.3125, 0.75  , ..., 0.8125, 0.    , 0.    ],\n",
            "        ...,\n",
            "        [0.    , 0.3125, 0.5   , ..., 0.3125, 0.625 , 0.    ],\n",
            "        [0.    , 0.    , 0.875 , ..., 0.875 , 0.375 , 0.    ],\n",
            "        [0.    , 0.    , 0.4375, ..., 0.625 , 0.    , 0.    ]],\n",
            "\n",
            "       [[0.    , 0.125 , 0.9375, ..., 0.    , 0.    , 0.    ],\n",
            "        [0.    , 0.3125, 1.    , ..., 0.    , 0.    , 0.    ],\n",
            "        [0.    , 0.5625, 0.9375, ..., 0.    , 0.    , 0.    ],\n",
            "        ...,\n",
            "        [0.    , 0.0625, 0.875 , ..., 0.    , 0.    , 0.    ],\n",
            "        [0.    , 0.25  , 1.    , ..., 1.    , 0.3125, 0.    ],\n",
            "        [0.    , 0.125 , 0.875 , ..., 0.5625, 0.0625, 0.    ]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0.    , 0.    , 0.5625, ..., 0.125 , 0.    , 0.    ],\n",
            "        [0.    , 0.    , 1.    , ..., 0.625 , 0.    , 0.    ],\n",
            "        [0.    , 0.    , 0.8125, ..., 1.    , 0.25  , 0.    ],\n",
            "        ...,\n",
            "        [0.    , 0.    , 0.    , ..., 0.5   , 0.375 , 0.    ],\n",
            "        [0.    , 0.    , 0.75  , ..., 0.8125, 0.1875, 0.    ],\n",
            "        [0.    , 0.    , 0.5   , ..., 0.5625, 0.    , 0.    ]],\n",
            "\n",
            "       [[0.    , 0.    , 0.4375, ..., 0.25  , 0.    , 0.    ],\n",
            "        [0.    , 0.    , 1.    , ..., 0.125 , 0.    , 0.    ],\n",
            "        [0.    , 0.25  , 0.8125, ..., 0.125 , 0.    , 0.    ],\n",
            "        ...,\n",
            "        [0.    , 0.    , 0.    , ..., 0.5   , 0.5   , 0.    ],\n",
            "        [0.    , 0.    , 0.6875, ..., 0.625 , 0.5   , 0.    ],\n",
            "        [0.    , 0.    , 0.5   , ..., 0.9375, 0.125 , 0.    ]],\n",
            "\n",
            "       [[0.    , 0.    , 0.25  , ..., 0.    , 0.    , 0.    ],\n",
            "        [0.    , 0.    , 0.1875, ..., 0.    , 0.    , 0.    ],\n",
            "        [0.    , 0.    , 0.125 , ..., 0.    , 0.    , 0.    ],\n",
            "        ...,\n",
            "        [0.    , 0.    , 0.    , ..., 0.625 , 0.    , 0.    ],\n",
            "        [0.    , 0.    , 0.25  , ..., 1.    , 0.8125, 0.8125],\n",
            "        [0.    , 0.    , 0.125 , ..., 1.    , 0.9375, 0.5   ]]])>, <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([5, 0, 2, 3, 8, 3, 1, 8, 4, 1, 3, 4, 1, 2, 0, 3, 0, 5, 0, 6, 6, 3,\n",
            "       9, 7, 7, 8, 9, 5, 5, 1, 1, 6, 3, 7, 5, 4, 9, 0, 4, 2, 4, 7, 5, 9,\n",
            "       5, 7, 7, 5, 2, 8, 1, 1, 5, 8, 1, 4, 7, 0, 4, 3, 5, 9, 5, 1])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3FsrFsbUUiU",
        "outputId": "458ebcb8-4fb3-4d6d-dc6d-e793ab4f67c1"
      },
      "source": [
        "#ignore this cell\n",
        "for item in train_ds.take(1):\n",
        "  in_shape = item[0].shape[1:]\n",
        "\n",
        "print(in_shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4co9buBMp4q"
      },
      "source": [
        "#specific that the input data shape is 8x8 (since the images are 8x8)\n",
        "#tensorflow with internally address the conversion so the 8x8 images\n",
        "#can be fed to 64 neurons of the input layer\n",
        "input_shape1 = (8,8)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nms67dG0LUGR",
        "outputId": "24313b59-75fb-4c55-e7e3-acf86d1a6c7c"
      },
      "source": [
        "print(input_shape1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9LmyqXaLg4u"
      },
      "source": [
        "#import modules from tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQqsq6tNLilU"
      },
      "source": [
        "#specific the structure of the model\n",
        "model = Sequential([Flatten(input_shape =input_shape1 ),Dense(256, activation=\"relu\"), Dense(10, activation=\"softmax\")])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAACc_IoMxx5",
        "outputId": "41aac682-ebcd-4538-e638-6e2db5d6641f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               16640     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19210 (75.04 KB)\n",
            "Trainable params: 19210 (75.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_QrB8VqMzj1"
      },
      "source": [
        "#specify the optimization, loss and metrics to be used during training (fit)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model and Test for Validation at the End of Each Epoch"
      ],
      "metadata": {
        "id": "c7uY8A8Y4mYI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_a0RjjaTSvb",
        "outputId": "76626b43-0221-4b6b-fbcc-daab3d70c31f"
      },
      "source": [
        "history = model.fit(train_ds, epochs=60, validation_data=(test_ds))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "19/19 [==============================] - 9s 13ms/step - loss: 2.0473 - accuracy: 0.4514 - val_loss: 1.7478 - val_accuracy: 0.7088\n",
            "Epoch 2/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4283 - accuracy: 0.8296 - val_loss: 1.2016 - val_accuracy: 0.8266\n",
            "Epoch 3/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9446 - accuracy: 0.8878 - val_loss: 0.8221 - val_accuracy: 0.8754\n",
            "Epoch 4/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.9077 - val_loss: 0.6058 - val_accuracy: 0.8906\n",
            "Epoch 5/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.9202 - val_loss: 0.4738 - val_accuracy: 0.9209\n",
            "Epoch 6/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.9327 - val_loss: 0.3933 - val_accuracy: 0.9276\n",
            "Epoch 7/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.9460 - val_loss: 0.3367 - val_accuracy: 0.9360\n",
            "Epoch 8/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2681 - accuracy: 0.9518 - val_loss: 0.2964 - val_accuracy: 0.9461\n",
            "Epoch 9/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2337 - accuracy: 0.9576 - val_loss: 0.2668 - val_accuracy: 0.9512\n",
            "Epoch 10/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2086 - accuracy: 0.9626 - val_loss: 0.2443 - val_accuracy: 0.9495\n",
            "Epoch 11/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1884 - accuracy: 0.9659 - val_loss: 0.2248 - val_accuracy: 0.9495\n",
            "Epoch 12/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1708 - accuracy: 0.9692 - val_loss: 0.2103 - val_accuracy: 0.9512\n",
            "Epoch 13/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1571 - accuracy: 0.9726 - val_loss: 0.1993 - val_accuracy: 0.9579\n",
            "Epoch 14/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1459 - accuracy: 0.9742 - val_loss: 0.1884 - val_accuracy: 0.9596\n",
            "Epoch 15/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1355 - accuracy: 0.9759 - val_loss: 0.1798 - val_accuracy: 0.9579\n",
            "Epoch 16/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.9800 - val_loss: 0.1709 - val_accuracy: 0.9630\n",
            "Epoch 17/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1184 - accuracy: 0.9792 - val_loss: 0.1647 - val_accuracy: 0.9630\n",
            "Epoch 18/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1115 - accuracy: 0.9809 - val_loss: 0.1595 - val_accuracy: 0.9613\n",
            "Epoch 19/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1054 - accuracy: 0.9834 - val_loss: 0.1536 - val_accuracy: 0.9680\n",
            "Epoch 20/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0999 - accuracy: 0.9850 - val_loss: 0.1498 - val_accuracy: 0.9663\n",
            "Epoch 21/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0934 - accuracy: 0.9859 - val_loss: 0.1440 - val_accuracy: 0.9697\n",
            "Epoch 22/60\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0892 - accuracy: 0.9867 - val_loss: 0.1426 - val_accuracy: 0.9680\n",
            "Epoch 23/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0841 - accuracy: 0.9867 - val_loss: 0.1390 - val_accuracy: 0.9697\n",
            "Epoch 24/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9884 - val_loss: 0.1340 - val_accuracy: 0.9714\n",
            "Epoch 25/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0761 - accuracy: 0.9875 - val_loss: 0.1318 - val_accuracy: 0.9747\n",
            "Epoch 26/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.9909 - val_loss: 0.1291 - val_accuracy: 0.9731\n",
            "Epoch 27/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.9909 - val_loss: 0.1270 - val_accuracy: 0.9731\n",
            "Epoch 28/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9925 - val_loss: 0.1243 - val_accuracy: 0.9731\n",
            "Epoch 29/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9933 - val_loss: 0.1215 - val_accuracy: 0.9731\n",
            "Epoch 30/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9950 - val_loss: 0.1200 - val_accuracy: 0.9747\n",
            "Epoch 31/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9942 - val_loss: 0.1179 - val_accuracy: 0.9731\n",
            "Epoch 32/60\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0543 - accuracy: 0.9950 - val_loss: 0.1178 - val_accuracy: 0.9714\n",
            "Epoch 33/60\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 0.9958 - val_loss: 0.1139 - val_accuracy: 0.9731\n",
            "Epoch 34/60\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0486 - accuracy: 0.9967 - val_loss: 0.1126 - val_accuracy: 0.9731\n",
            "Epoch 35/60\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.0465 - accuracy: 0.9967 - val_loss: 0.1117 - val_accuracy: 0.9747\n",
            "Epoch 36/60\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.0444 - accuracy: 0.9967 - val_loss: 0.1097 - val_accuracy: 0.9731\n",
            "Epoch 37/60\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.0428 - accuracy: 0.9967 - val_loss: 0.1089 - val_accuracy: 0.9731\n",
            "Epoch 38/60\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0408 - accuracy: 0.9967 - val_loss: 0.1074 - val_accuracy: 0.9747\n",
            "Epoch 39/60\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9967 - val_loss: 0.1059 - val_accuracy: 0.9731\n",
            "Epoch 40/60\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.0373 - accuracy: 0.9975 - val_loss: 0.1059 - val_accuracy: 0.9747\n",
            "Epoch 41/60\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0360 - accuracy: 0.9975 - val_loss: 0.1042 - val_accuracy: 0.9731\n",
            "Epoch 42/60\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.0341 - accuracy: 0.9975 - val_loss: 0.1028 - val_accuracy: 0.9747\n",
            "Epoch 43/60\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.0331 - accuracy: 0.9975 - val_loss: 0.1018 - val_accuracy: 0.9747\n",
            "Epoch 44/60\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0316 - accuracy: 0.9975 - val_loss: 0.1020 - val_accuracy: 0.9731\n",
            "Epoch 45/60\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0304 - accuracy: 0.9975 - val_loss: 0.1004 - val_accuracy: 0.9747\n",
            "Epoch 46/60\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0291 - accuracy: 0.9983 - val_loss: 0.0995 - val_accuracy: 0.9731\n",
            "Epoch 47/60\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0279 - accuracy: 0.9983 - val_loss: 0.0992 - val_accuracy: 0.9747\n",
            "Epoch 48/60\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.0268 - accuracy: 0.9983 - val_loss: 0.0996 - val_accuracy: 0.9764\n",
            "Epoch 49/60\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9983 - val_loss: 0.0975 - val_accuracy: 0.9764\n",
            "Epoch 50/60\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9983 - val_loss: 0.0967 - val_accuracy: 0.9781\n",
            "Epoch 51/60\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0243 - accuracy: 0.9983 - val_loss: 0.0976 - val_accuracy: 0.9781\n",
            "Epoch 52/60\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9983 - val_loss: 0.0967 - val_accuracy: 0.9781\n",
            "Epoch 53/60\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9983 - val_loss: 0.0967 - val_accuracy: 0.9798\n",
            "Epoch 54/60\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.0214 - accuracy: 0.9992 - val_loss: 0.0963 - val_accuracy: 0.9781\n",
            "Epoch 55/60\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9781\n",
            "Epoch 56/60\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9992 - val_loss: 0.0947 - val_accuracy: 0.9798\n",
            "Epoch 57/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9798\n",
            "Epoch 58/60\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0188 - accuracy: 0.9992 - val_loss: 0.0943 - val_accuracy: 0.9798\n",
            "Epoch 59/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9781\n",
            "Epoch 60/60\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzbghurWT20N",
        "outputId": "aa4fe2ec-82aa-4223-c2f1-fc3865c4da7e"
      },
      "source": [
        "#find the accuracy of the trained model against the test data set.\n",
        "model.evaluate(test_ds)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0922 - accuracy: 0.9798\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09222365915775299, 0.9797979593276978]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mef-rm2UZsNe"
      },
      "source": [],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b17Q2MAJCeUM"
      },
      "source": [],
      "execution_count": 38,
      "outputs": []
    }
  ]
}